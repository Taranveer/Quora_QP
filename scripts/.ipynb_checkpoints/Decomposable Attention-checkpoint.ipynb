{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import dynet as dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss after 1 epochs: 0.701264912306\n",
      "Train loss after 2 epochs: 0.0960322426866\n",
      "Train loss after 3 epochs: 0.0179971929838\n",
      "Train loss after 4 epochs: 0.0065578334452\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3dd8dd3da913>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-3dd8dd3da913>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecomposable_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-3dd8dd3da913>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_log_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m                 \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0mtl\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#def similarity():\n",
    "    \n",
    "#data is already in data numpy matrix\n",
    "\n",
    "class decomposable_attention():\n",
    "    def __init__(self,embedding_dim,debug=False):\n",
    "        self.pc = dy.Model()\n",
    "        self.debug = debug\n",
    "        self.embedding_dim = embedding_dim \n",
    "        self.embedding_matrix = self.pc.add_lookup_parameters((16800,embedding_dim))\n",
    "        self.data1 = np.random.randint(16800,size=(10000,50))\n",
    "        self.data2 = np.random.randint(16800,size=(10000,50))\n",
    "        self.len1 = 1+np.random.randint(50,size=10000)\n",
    "        self.len2 = 1+np.random.randint(50,size=10000)\n",
    "        self.labels = np.random.randint(2,size=10000)\n",
    "        \n",
    "        self.w2 = self.pc.add_parameters((embedding_dim,2*embedding_dim))\n",
    "        self.b2 = self.pc.add_parameters((embedding_dim,1))\n",
    "        \n",
    "        self.w3 = self.pc.add_parameters((embedding_dim,2*embedding_dim))\n",
    "        self.b3 = self.pc.add_parameters((embedding_dim,1))\n",
    "        \n",
    "        self.w = self.pc.add_parameters((1,2*embedding_dim))\n",
    "        self.b = self.pc.add_parameters((1,1))\n",
    "        \n",
    "        \n",
    "    def forward(self,x1,x2,label,k,tl):\n",
    "        \n",
    "        debug = self.debug\n",
    "        len1 = self.len1\n",
    "        len2 = self.len2\n",
    "        embedding_dim = self.embedding_dim\n",
    "        \n",
    "        w = dy.parameter(self.w)\n",
    "        b = dy.parameter(self.b)\n",
    "        w2 = dy.parameter(self.w2)\n",
    "        b2 = dy.parameter(self.b2)\n",
    "        w3 = dy.parameter(self.w3)\n",
    "        b3 = dy.parameter(self.b3)\n",
    "        \n",
    "        embeds1 = dy.reshape(dy.lookup_batch(self.embedding_matrix,x1),(len1[k],embedding_dim))\n",
    "        embeds2 = dy.reshape(dy.lookup_batch(self.embedding_matrix,x2),(len2[k],embedding_dim))\n",
    "\n",
    "        if debug:\n",
    "            print('embedding 1:', (len1[k],embedding_dim), embeds1.dim())\n",
    "            print('embedding 2:', (embedding_dim,len2[k]), embeds2.dim())\n",
    "\n",
    "        similarity = embeds1*dy.transpose(embeds2)\n",
    "        if debug:\n",
    "            print('similarity dimension:', (len1[k],len2[k]), similarity.dim())\n",
    "\n",
    "        n_a = dy.softmax(similarity,d=0)\n",
    "        n_b = dy.softmax(similarity,d=1)\n",
    "        \n",
    "        alpha = dy.transpose(n_a)*embeds1\n",
    "        beta = n_b*embeds2\n",
    "        \n",
    "        if debug:\n",
    "            print('alpha:',(len2[k],embedding_dim), alpha.dim())\n",
    "            print('beta:',(len1[k],embedding_dim), beta.dim())\n",
    "            \n",
    "        v1i = w2*dy.transpose(dy.concatenate_cols([embeds1,beta])) + b2\n",
    "        v2j = w3*dy.transpose(dy.concatenate_cols([embeds2,alpha])) + b3\n",
    "        if debug:\n",
    "            print('v1:', (embedding_dim,len1[k]), v1i.dim())\n",
    "            print('v2:', (embedding_dim,len2[k]), v2j.dim())\n",
    "        \n",
    "        v1 = dy.mean_dim(v1i,[1],0)\n",
    "        v1 = dy.reshape(v1,(embedding_dim,1)) \n",
    "        \n",
    "        v2 = dy.mean_dim(v2j,[1],0)\n",
    "        v2 = dy.reshape(v2,(embedding_dim,1)) \n",
    "        \n",
    "        score = w*dy.concatenate([v1,v2],d=0) + b\n",
    "        \n",
    "        return score\n",
    "        \n",
    "    def train(self):\n",
    "        len1 = self.len1\n",
    "        len2 = self.len2\n",
    "        embedding_dim = self.embedding_dim\n",
    "        \n",
    "        trainer = dy.AdamTrainer(self.pc)\n",
    "        \n",
    "        iter = 0\n",
    "        for epochs in range(100):\n",
    "            tl = 0\n",
    "            for k in range(10000):\n",
    "                iter += 1\n",
    "                dy.renew_cg()\n",
    "                x1 = self.data1[k,0:len1[k]]\n",
    "                x2 = self.data2[k,0:len2[k]]\n",
    "                label = self.labels[k]\n",
    "\n",
    "                score = self.forward(x1,x2,label,k,tl)\n",
    "                norm_score = dy.logistic(score)\n",
    "                \n",
    "                loss = dy.binary_log_loss(norm_score,dy.inputTensor([[label]]))\n",
    "                loss.backward()\n",
    "                trainer.update()\n",
    "                tl += loss.scalar_value()\n",
    "                #if iter % dev_iter == 0:\n",
    "                    #predict_fn\n",
    "                    \n",
    "            print('Train loss after ' + str(epochs+1) + ' epochs: ' + str(tl/10000))\n",
    "\n",
    "def main():\n",
    "    model = decomposable_attention(embedding_dim=128,debug=False)\n",
    "    model.train()\n",
    "    \n",
    "main()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mismatched input dimensions in MatrixMultiply: [{222X10} {222X15}]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-165fff488ca1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_dynet.pyx\u001b[0m in \u001b[0;36m_dynet.Expression.__mul__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_dynet.pyx\u001b[0m in \u001b[0;36m_dynet._mul\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Mismatched input dimensions in MatrixMultiply: [{222X10} {222X15}]"
     ]
    }
   ],
   "source": [
    "x1 = np.random.randint(5,size=10)\n",
    "x2 = np.random.randint(5,size=15)\n",
    "\n",
    "pc = dy.Model()\n",
    "embedding_matrix = pc.add_lookup_parameters((168000,222))\n",
    "a = dy.lookup_batch(embedding_matrix,x1)\n",
    "b = dy.lookup_batch(embedding_matrix,x2)\n",
    "\n",
    "c = a*b\n",
    "print(c.dim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.48167747, -0.07805443, -0.22833993,  0.49472263, -0.24113466,\n",
       "        0.788912  ,  0.25677112, -0.74309444])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pc = dy.Model()\n",
    "s = pc.add_parameters((4))\n",
    "s1 = pc.add_parameters((4))\n",
    "\n",
    "dy.renew_cg()\n",
    "sa = dy.parameter(s)\n",
    "sb = dy.parameter(s1)\n",
    "na = dy.concatenate([sa,sb])\n",
    "na.npvalue()\n",
    "#n_b = dy.softmax(similarity,d=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
