{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Training and test corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = \"../../\"\n",
    "train = pd.read_csv(data_path + \"train.csv\")[:10000]\n",
    "test = pd.read_csv(data_path + \"test.csv\")[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = \"../corpus/\"\n",
    "s = pickle.load(open(data_path + \"sentences_train_10000.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = list(train[\"is_duplicate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"../\"\n",
    "predPair_5 = pickle.load(open(data_path + \"predictions/predPair_5.pkl\"))\n",
    "predPair_5_dup = map(lambda x: x[2], predPair_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.42      0.53      6289\n",
      "          1       0.43      0.74      0.54      3711\n",
      "\n",
      "avg / total       0.62      0.54      0.54     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = predPair_5_dup\n",
    "print classification_report(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sDist = pickle.load(open(\"../predictions/sDist.pkl\"))\n",
    "sDist = map(lambda x: x[0][0], sDist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.36723104],\n",
       "       [ 0.36723104,  1.        ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(sDist, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SDist Prob - Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sDist = np.array(sDist)\n",
    "sDist_prob = ((sDist - (-1)*(1 - 0))/(1 - (-1))) + 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72315383106157016"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "y = np.array(y_true)\n",
    "pred = np.array(sDist_prob)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y, pred, pos_label=1)\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.51      0.63      6289\n",
      "          1       0.50      0.81      0.62      3711\n",
      "\n",
      "avg / total       0.70      0.62      0.63     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mu = np.mean(sDist)\n",
    "y_pred  = (sDist >= mu) + 0\n",
    "print classification_report(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnt_0_0 = 0\n",
    "cnt_0_1 = 0\n",
    "cnt_1_0 = 0\n",
    "cnt_1_1 = 0\n",
    "for i in range(0,10000):\n",
    "    if y_true[i] == 1 and y_pred[i] == 1:\n",
    "        cnt_1_1 +=1\n",
    "    if y_true[i] == 1 and y_pred[i] == 0:\n",
    "        cnt_1_0 +=1\n",
    "    if y_true[i] == 0 and y_pred[i] == 1:\n",
    "        cnt_0_1 +=1\n",
    "    if y_true[i] == 0 and y_pred[i] == 0:\n",
    "        cnt_0_0 +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3229, 3060],\n",
       "       [ 699, 3012]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[cnt_0_0, cnt_0_1], [cnt_1_0, cnt_1_1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      1.00      0.77      6289\n",
      "          1       0.00      0.00      0.00      3711\n",
      "\n",
      "avg / total       0.40      0.63      0.49     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_dummy = np.zeros((10000,))\n",
    "y_pred_dummy = list(y_pred_dummy)\n",
    "print classification_report(y_true, y_pred_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00      6289\n",
      "          1       0.37      1.00      0.54      3711\n",
      "\n",
      "avg / total       0.14      0.37      0.20     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_dummy = np.ones((10000,))\n",
    "y_pred_dummy = list(y_pred_dummy)\n",
    "print classification_report(y_true, y_pred_dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "\n",
    "1. We reduced 1 (duplicates) being missclassified as 0 (not duplicates)\n",
    "2. We are pretty good at detecting 1's (duplicates) \n",
    "3. lot of non-duplicates are classified as duplicates because we are not getting rid of missclassifications\n",
    "\n",
    "What we are concerned as a user is we should not miss out on duplicates recall of duplicates(1) should be high. Then user can make a choice... We dont wanna miss out on opportunity cost of gettting a good answer on a duplicate question. But then we also have limited window size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Analysis File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train[\"pred\"] = y_pred\n",
    "#train[\"prob\"] = sDist\n",
    "#train.to_csv(\"../predictions/train_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
